{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tokenize import tokenize\n",
    "\n",
    "# Import module from gsdmm repository\n",
    "sys.path.insert(0, '../gsdmm/')\n",
    "from gsdmm import MovieGroupProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>timezone</th>\n",
       "      <th>tweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>retweet</th>\n",
       "      <th>nlikes</th>\n",
       "      <th>nreplies</th>\n",
       "      <th>nretweets</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1244004590699384833</td>\n",
       "      <td>2020-03-28 20:53:01</td>\n",
       "      <td>UTC</td>\n",
       "      <td>Schlifke said, he and members of the CovidVent...</td>\n",
       "      <td>['#covid19']</td>\n",
       "      <td>KHNews</td>\n",
       "      <td>Kaiser Health News</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>schlifke say members covidvent coalition help ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1243979929437507585</td>\n",
       "      <td>2020-03-28 19:15:01</td>\n",
       "      <td>UTC</td>\n",
       "      <td>Millions of Americans are seeking care by conn...</td>\n",
       "      <td>['#covid19', '#telemedicine']</td>\n",
       "      <td>KHNews</td>\n",
       "      <td>Kaiser Health News</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>millions americans seek care connect doctor el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1243956772123090944</td>\n",
       "      <td>2020-03-28 17:43:00</td>\n",
       "      <td>UTC</td>\n",
       "      <td>We're following the #coronaviruspandemic close...</td>\n",
       "      <td>['#coronaviruspandemic', '#healthcare', '#heal...</td>\n",
       "      <td>KHNews</td>\n",
       "      <td>Kaiser Health News</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>follow closely bring best investigation surrou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1243941673270460418</td>\n",
       "      <td>2020-03-28 16:43:00</td>\n",
       "      <td>UTC</td>\n",
       "      <td>About $100 billion of the funding is intended ...</td>\n",
       "      <td>['#coronavirus', '#relieffunds', '#healthbent']</td>\n",
       "      <td>KHNews</td>\n",
       "      <td>Kaiser Health News</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>billion fund intend put reimburse eligible hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1243911473480556544</td>\n",
       "      <td>2020-03-28 14:43:00</td>\n",
       "      <td>UTC</td>\n",
       "      <td>Read KHN's top #COVID19 coverage: The U.S. mil...</td>\n",
       "      <td>['#covid19']</td>\n",
       "      <td>KHNews</td>\n",
       "      <td>Kaiser Health News</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>read coverage military fly specialize swab ita...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                 date timezone  \\\n",
       "0  1244004590699384833  2020-03-28 20:53:01      UTC   \n",
       "1  1243979929437507585  2020-03-28 19:15:01      UTC   \n",
       "2  1243956772123090944  2020-03-28 17:43:00      UTC   \n",
       "3  1243941673270460418  2020-03-28 16:43:00      UTC   \n",
       "4  1243911473480556544  2020-03-28 14:43:00      UTC   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  Schlifke said, he and members of the CovidVent...   \n",
       "1  Millions of Americans are seeking care by conn...   \n",
       "2  We're following the #coronaviruspandemic close...   \n",
       "3  About $100 billion of the funding is intended ...   \n",
       "4  Read KHN's top #COVID19 coverage: The U.S. mil...   \n",
       "\n",
       "                                            hashtags username  \\\n",
       "0                                       ['#covid19']   KHNews   \n",
       "1                      ['#covid19', '#telemedicine']   KHNews   \n",
       "2  ['#coronaviruspandemic', '#healthcare', '#heal...   KHNews   \n",
       "3    ['#coronavirus', '#relieffunds', '#healthbent']   KHNews   \n",
       "4                                       ['#covid19']   KHNews   \n",
       "\n",
       "                 name  day  hour  retweet  nlikes  nreplies  nretweets  \\\n",
       "0  Kaiser Health News    4     3    False       0         0          1   \n",
       "1  Kaiser Health News    6     2    False       6         0          2   \n",
       "2  Kaiser Health News    5     4    False       0         0          1   \n",
       "3  Kaiser Health News    5    12    False       1         0          1   \n",
       "4  Kaiser Health News    6     4    False       4         1          7   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0  schlifke say members covidvent coalition help ...  \n",
       "1  millions americans seek care connect doctor el...  \n",
       "2  follow closely bring best investigation surrou...  \n",
       "3  billion fund intend put reimburse eligible hea...  \n",
       "4  read coverage military fly specialize swab ita...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import customs module to tokenize and clean tweet dataset\n",
    "from clean_tokenizer import tokenize_tweets\n",
    "data_dir = '../input/english_health_tweets.csv'\n",
    "tweets_df = pd.read_csv(data_dir) # to be used with cleaned tokenized english only csv\n",
    "# tweets_df = tokenize_tweets(data_dir) # to be used with non-clean raw health tweets csv\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short Term Text Modeling (STTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert cleaned tweet into tokens list\n",
    "tweets_df['clean_tokens'] = tweets_df.clean_tweet.apply(lambda x: re.split('\\s', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of tweet tokens\n",
    "docs = tweets_df['clean_tokens'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In stage 0: transferred 161638 clusters with 13 clusters populated\n",
      "In stage 1: transferred 125678 clusters with 13 clusters populated\n",
      "In stage 2: transferred 89367 clusters with 13 clusters populated\n",
      "In stage 3: transferred 65696 clusters with 13 clusters populated\n",
      "In stage 4: transferred 54166 clusters with 13 clusters populated\n",
      "In stage 5: transferred 48752 clusters with 13 clusters populated\n",
      "In stage 6: transferred 45499 clusters with 13 clusters populated\n",
      "In stage 7: transferred 43169 clusters with 13 clusters populated\n",
      "In stage 8: transferred 41604 clusters with 13 clusters populated\n",
      "In stage 9: transferred 40111 clusters with 13 clusters populated\n",
      "In stage 10: transferred 39128 clusters with 13 clusters populated\n",
      "In stage 11: transferred 38576 clusters with 13 clusters populated\n",
      "In stage 12: transferred 37981 clusters with 13 clusters populated\n",
      "In stage 13: transferred 37167 clusters with 13 clusters populated\n",
      "In stage 14: transferred 36776 clusters with 13 clusters populated\n",
      "In stage 15: transferred 36552 clusters with 13 clusters populated\n",
      "In stage 16: transferred 36349 clusters with 13 clusters populated\n",
      "In stage 17: transferred 35641 clusters with 13 clusters populated\n",
      "In stage 18: transferred 35410 clusters with 13 clusters populated\n",
      "In stage 19: transferred 35528 clusters with 13 clusters populated\n",
      "In stage 20: transferred 35367 clusters with 13 clusters populated\n",
      "In stage 21: transferred 35189 clusters with 13 clusters populated\n",
      "In stage 22: transferred 35144 clusters with 13 clusters populated\n",
      "In stage 23: transferred 34827 clusters with 13 clusters populated\n",
      "In stage 24: transferred 34431 clusters with 13 clusters populated\n",
      "In stage 25: transferred 34114 clusters with 13 clusters populated\n",
      "In stage 26: transferred 34352 clusters with 13 clusters populated\n",
      "In stage 27: transferred 34111 clusters with 13 clusters populated\n",
      "In stage 28: transferred 33950 clusters with 13 clusters populated\n",
      "In stage 29: transferred 34094 clusters with 13 clusters populated\n",
      "Wall time: 30min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train STTM model\n",
    "# Init of the Gibbs Sampling Dirichlet Mixture Model algorithm\n",
    "# K = number of potential topic (which we don't know a priori)\n",
    "# alpha = \n",
    "# beta = \n",
    "# n_iters = number of iterations to \n",
    "mgp = MovieGroupProcess(K=10, alpha=0.1, beta=0.1, n_iters=30)\n",
    "vocab = set(x for doc in docs for x in doc)\n",
    "n_terms = len(vocab)\n",
    "y = mgp.fit(docs, n_terms)\n",
    "\n",
    "# Save model\n",
    "with open('dumps/trained_models/v3.model', 'wb') as f:\n",
    "    pickle.dump(mgp, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in trained model with 10 topics \n",
    "filehandler = open('dumps/trained_models/v1.model', 'rb')\n",
    "mgp = pickle.load(filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def top_words(cluster_word_distribution, top_cluster, values):\n",
    "    for cluster in top_cluster:\n",
    "        sort_dicts =sorted(mgp.cluster_word_distribution[cluster].items(), key=lambda k: k[1], reverse=True)[:values]\n",
    "        print('Cluster %s : %s'%(cluster,sort_dicts))\n",
    "        print(' — — — — — — — — —')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents per topic : [18387 21321 18434 22806 20195 26692 26134  8562  6816 13494]\n",
      "********************\n",
      "Most important clusters (by number of docs inside): [5 6 3 1 4 2 0 9 7 8]\n",
      "********************\n",
      "Cluster 5 : [('help', 2031), ('diet', 1855), ('healthy', 1701), ('health', 1539), ('weight', 1456)]\n",
      " — — — — — — — — —\n",
      "Cluster 6 : [('health', 3405), ('care', 3100), ('doctor', 2999), ('patients', 2380), ('nurse', 1654)]\n",
      " — — — — — — — — —\n",
      "Cluster 3 : [('study', 3204), ('risk', 1917), ('health', 1601), ('say', 1562), ('kid', 1401)]\n",
      " — — — — — — — — —\n",
      "Cluster 1 : [('ebola', 3734), ('case', 2347), ('coronavirus', 2330), ('outbreak', 2280), ('zika', 1851)]\n",
      " — — — — — — — — —\n",
      "Cluster 4 : [('cancer', 4738), ('study', 2504), ('drug', 2017), ('risk', 1852), ('disease', 1664)]\n",
      " — — — — — — — — —\n",
      "Cluster 2 : [('baby', 1176), ('woman', 1131), ('die', 1081), ('cancer', 1022), ('year', 941)]\n",
      " — — — — — — — — —\n",
      "Cluster 0 : [('health', 6114), ('care', 2585), ('plan', 1651), ('obamacare', 1597), ('trump', 1421)]\n",
      " — — — — — — — — —\n",
      "Cluster 9 : [('drug', 4845), ('cancer', 1194), ('opioid', 1070), ('price', 1020), ('say', 1012)]\n",
      " — — — — — — — — —\n",
      "Cluster 7 : [('abortion', 915), ('state', 680), ('court', 558), ('rule', 469), ('health', 423)]\n",
      " — — — — — — — — —\n",
      "Cluster 8 : [('health', 646), ('cigarettes', 622), ('tobacco', 554), ('say', 551), ('vaping', 411)]\n",
      " — — — — — — — — —\n"
     ]
    }
   ],
   "source": [
    "doc_count = np.array(mgp.cluster_doc_count)\n",
    "print('Number of documents per topic :', doc_count)\n",
    "print('*'*20)\n",
    "# Topics sorted by the number of document they are allocated to\n",
    "top_index = doc_count.argsort()[-10:][::-1]\n",
    "print('Most important clusters (by number of docs inside):', top_index)\n",
    "print('*'*20)\n",
    "# Show the top 5 words in term frequency for each cluster \n",
    "top_words(mgp.cluster_word_distribution, top_index, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get the word importance for each topic\n",
    "def cluster_importance(mgp):\n",
    "    n_z_w = mgp.cluster_word_distribution\n",
    "    beta, V, K = mgp.beta, mgp.vocab_size, mgp.K\n",
    "    phi = [{} for i in range(K)]        \n",
    "    for z in range(K):\n",
    "        for w in n_z_w[z]:\n",
    "            phi[z][w] = (n_z_w[z][w]+beta)/(sum(n_z_w[z].values())+V*beta)\n",
    "    return phi\n",
    "phi = cluster_importance(mgp)\n",
    "\n",
    "# phi[i][w] would be the importance of word w in topic i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025117225152337205"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi[1]['ebola'] # verify for topic 2 on virus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to attribute topics to documents\n",
    "# def topic_attribution(data, model, topic_dict, threshold):\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_dict = {}\n",
    "# topic_names = ['diet and excercise',\n",
    "#                'health and medical workers',\n",
    "#                'miscellaneous studies affecting women/children',\n",
    "#                'virus/outbreaks',\n",
    "#                'cancer and heart disease',\n",
    "#                'cancer studies affecting woman/babies',\n",
    "#                'health insurance',\n",
    "#                'drug costs and opiod crisis',\n",
    "#                'abortion',\n",
    "#                'vaping and cigarettes']\n",
    "\n",
    "# for i, topic_num in enumerate(top_index):\n",
    "#     topic_dict[topic_num]=topic_names[i] \n",
    "    \n",
    "# # Create dataframe \n",
    "# pred_df = topic_attribution(tweets_df, mgp, topic_dict, threshold=0.4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
